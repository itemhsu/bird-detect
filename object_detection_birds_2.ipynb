{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "## Step 0: Set training constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::966911974471:role/service-role/AmazonSageMaker-ExecutionRole-20200922T113651\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import conf\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = conf.prefix + '/train'\n",
    "validation_channel = conf.prefix + '/validation'\n",
    "s3_train_data = 's3://{}/{}'.format(conf.bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(conf.bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define an output location in S3, where the model artifacts will be placed on completion of the training. These artifacts are the output of the algorithm's traning job.  We also get the URI to the Amazon SageMaker Object Detection docker image.  This ensures the estimator uses the correct algorithm from the current region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(conf.bucket, conf.prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/object-detection:1\n"
     ]
    }
   ],
   "source": [
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import image_uris\n",
    "sess = sagemaker.Session()\n",
    "#training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version='latest')\n",
    "region=sess.boto_region_name\n",
    "training_image = image_uris.retrieve('object-detection',region)\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         instance_count=1, \n",
    "                                         instance_type='ml.p3.16xlarge',\n",
    "                                         volume_size = 50,\n",
    "                                         max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hyperparameters(num_epochs, lr_steps, num_classes, train_df):\n",
    "\n",
    "    num_training_samples = train_df\n",
    "    print('num epochs: {}, num classes: {}, num training images: {}'.format(num_epochs, num_classes, num_training_samples))\n",
    "\n",
    "    od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                                 use_pretrained_model=1,\n",
    "                                 num_classes=num_classes,\n",
    "                                 mini_batch_size=16,\n",
    "                                 epochs=num_epochs,               \n",
    "                                 learning_rate=0.001, \n",
    "                                 lr_scheduler_step=lr_steps,      \n",
    "                                 lr_scheduler_factor=0.1,\n",
    "                                 optimizer='sgd',\n",
    "                                 momentum=0.9,\n",
    "                                 weight_decay=0.0005,\n",
    "                                 overlap_threshold=0.5,\n",
    "                                 nms_threshold=0.45,\n",
    "                                 image_shape=512,\n",
    "                                 label_width=350,\n",
    "                                 num_training_samples=num_training_samples)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num epochs: 10, num classes: 1, num training images: 9430\n"
     ]
    }
   ],
   "source": [
    "set_hyperparameters(conf.num_epochs, '33,67',conf.num_classes, conf.train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the hyperparameters are setup, we define the data channels to be passed to the algorithm. To do this, we need to create the `sagemaker.session.s3_input` objects from our data channels. These objects are then put in a simple dictionary, which the algorithm consumes.  Note that you could add a third channel named `model` to perform incremental training (continue training from where you had left off with a prior model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.inputs.TrainingInput(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Submit training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-26 07:27:11 Starting - Starting the training job...\n",
      "2020-11-26 07:27:13 Starting - Launching requested ML instances.........\n",
      "2020-11-26 07:28:57 Starting - Preparing the instances for training......\n",
      "2020-11-26 07:30:09 Downloading - Downloading input data...\n",
      "2020-11-26 07:30:25 Training - Downloading the training image......\n",
      "2020-11-26 07:31:28 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'0', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'', u'base_network': u'vgg-16', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'epochs': u'10', u'nms_threshold': u'0.45', u'optimizer': u'sgd', u'base_network': u'resnet-50', u'image_shape': u'512', u'label_width': u'350', u'lr_scheduler_step': u'33,67', u'momentum': u'0.9', u'overlap_threshold': u'0.5', u'num_training_samples': u'9430', u'mini_batch_size': u'16', u'weight_decay': u'0.0005', u'use_pretrained_model': u'1', u'num_classes': u'1', u'lr_scheduler_factor': u'0.1'}\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Final configuration: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'10', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'16', u'use_pretrained_model': u'1', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'33,67', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'9430', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'1', u'base_network': u'resnet-50', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'512'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Using default worker.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:30 INFO 140004883121984] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:31 INFO 140004883121984] nvidia-smi took: 0.100771903992 secs to identify 8 gpus\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:31 INFO 140004883121984] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:31 WARNING 140004883121984] Training images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[07:31:31] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/birds_ssd_train.rec, use 48 threads for decoding..\u001b[0m\n",
      "\u001b[34m[07:31:31] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/birds_ssd_train.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:34 WARNING 140004883121984] Validation images are resized to image shape (3, 512, 512)\u001b[0m\n",
      "\u001b[34m[07:31:34] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/birds_ssd_val.rec, use 32 threads for decoding..\u001b[0m\n",
      "\u001b[34m[07:31:34] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/birds_ssd_val.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Using [gpu(0),gpu(1),gpu(2),gpu(3),gpu(4),gpu(5),gpu(6),gpu(7)] as training context.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Create Store: device\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Using (gpu(0),gpu(1),gpu(2),gpu(3),gpu(4),gpu(5),gpu(6),gpu(7)) as training context.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:38 INFO 140004883121984] Start training from pretrained model 1.\u001b[0m\n",
      "\u001b[34m[07:31:38] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[07:31:38] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:31:39 INFO 140004883121984] Loaded pretrained model parameters.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:32:09 INFO 140004883121984] Creating a new state instance.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1606375929.996899, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1606375929.996838}\n",
      "\u001b[0m\n",
      "\u001b[34m[07:32:10] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:744: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: .vvvv...\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: v.vv.v..\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: vv.v..v.\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: vvv....v\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: v....vvv\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: .v..v.vv\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: ..v.vv.v\u001b[0m\n",
      "\u001b[34m[07:32:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_9.x.42.0/AL2012/generic-flavor/src/src/kvstore/././comm.h:753: ...vvvv.\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:32:36 INFO 140004883121984] Epoch:    0, batches:    100, num_examples:   1600, 60.3 samples/sec, epoch time so far:  0:00:26.534011\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:32:59 INFO 140004883121984] Epoch:    0, batches:    200, num_examples:   3200, 65.0 samples/sec, epoch time so far:  0:00:49.211282\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:33:21 INFO 140004883121984] Epoch:    0, batches:    300, num_examples:   4800, 67.2 samples/sec, epoch time so far:  0:01:11.409783\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:33:42 INFO 140004883121984] Epoch:    0, batches:    400, num_examples:   6400, 68.9 samples/sec, epoch time so far:  0:01:32.935740\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:06 INFO 140004883121984] Epoch:    0, batches:    500, num_examples:   8000, 68.8 samples/sec, epoch time so far:  0:01:56.250862\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:25 INFO 140004883121984] #quality_metric: host=algo-1, epoch=0, batch=590 train cross_entropy <loss>=(0.6441554851949781)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:25 INFO 140004883121984] #quality_metric: host=algo-1, epoch=0, batch=590 train smooth_l1 <loss>=(0.5968847591883484)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:25 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:26 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:47 INFO 140004883121984] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(0.3892038647538077)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:47 INFO 140004883121984] Updating the best model with validation-mAP=0.3892038647538077\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:47 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:34:47 INFO 140004883121984] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606376087.669404, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 0}, \"StartTime\": 1606375929.997152}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:35:09 INFO 140004883121984] Epoch:    1, batches:    100, num_examples:   1600, 72.5 samples/sec, epoch time so far:  0:00:22.056000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[11/26/2020 07:35:31 INFO 140004883121984] Epoch:    1, batches:    200, num_examples:   3200, 72.5 samples/sec, epoch time so far:  0:00:44.156634\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:35:54 INFO 140004883121984] Epoch:    1, batches:    300, num_examples:   4800, 72.0 samples/sec, epoch time so far:  0:01:06.649642\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:17 INFO 140004883121984] Epoch:    1, batches:    400, num_examples:   6400, 71.6 samples/sec, epoch time so far:  0:01:29.382622\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:38 INFO 140004883121984] Epoch:    1, batches:    500, num_examples:   8000, 72.0 samples/sec, epoch time so far:  0:01:51.140679\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:58 INFO 140004883121984] #quality_metric: host=algo-1, epoch=1, batch=589 train cross_entropy <loss>=(0.5570799104433422)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:58 INFO 140004883121984] #quality_metric: host=algo-1, epoch=1, batch=589 train smooth_l1 <loss>=(0.4539318011282833)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:58 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:36:58 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:37:22 INFO 140004883121984] #quality_metric: host=algo-1, epoch=1, validation mAP <score>=(0.6244389145438317)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:37:22 INFO 140004883121984] Updating the best model with validation-mAP=0.6244389145438317\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:37:22 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:37:22 INFO 140004883121984] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1606376242.804887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 1}, \"StartTime\": 1606376087.669569}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:37:44 INFO 140004883121984] Epoch:    2, batches:    100, num_examples:   1600, 73.0 samples/sec, epoch time so far:  0:00:21.931177\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:38:07 INFO 140004883121984] Epoch:    2, batches:    200, num_examples:   3200, 72.1 samples/sec, epoch time so far:  0:00:44.386667\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:38:29 INFO 140004883121984] Epoch:    2, batches:    300, num_examples:   4800, 72.1 samples/sec, epoch time so far:  0:01:06.571656\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:38:51 INFO 140004883121984] Epoch:    2, batches:    400, num_examples:   6400, 72.2 samples/sec, epoch time so far:  0:01:28.688595\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:13 INFO 140004883121984] Epoch:    2, batches:    500, num_examples:   8000, 72.0 samples/sec, epoch time so far:  0:01:51.157187\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:33 INFO 140004883121984] #quality_metric: host=algo-1, epoch=2, batch=590 train cross_entropy <loss>=(0.523000019807809)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:33 INFO 140004883121984] #quality_metric: host=algo-1, epoch=2, batch=590 train smooth_l1 <loss>=(0.36008304012641995)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:33 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:34 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:59 INFO 140004883121984] #quality_metric: host=algo-1, epoch=2, validation mAP <score>=(0.8490693877565119)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:59 INFO 140004883121984] Updating the best model with validation-mAP=0.8490693877565119\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:59 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:39:59 INFO 140004883121984] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1606376399.772983, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 2}, \"StartTime\": 1606376242.805038}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:40:22 INFO 140004883121984] Epoch:    3, batches:    100, num_examples:   1600, 71.3 samples/sec, epoch time so far:  0:00:22.455843\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:40:45 INFO 140004883121984] Epoch:    3, batches:    200, num_examples:   3200, 70.2 samples/sec, epoch time so far:  0:00:45.557702\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:41:07 INFO 140004883121984] Epoch:    3, batches:    300, num_examples:   4800, 71.1 samples/sec, epoch time so far:  0:01:07.518576\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:41:29 INFO 140004883121984] Epoch:    3, batches:    400, num_examples:   6400, 71.1 samples/sec, epoch time so far:  0:01:29.957370\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:41:51 INFO 140004883121984] Epoch:    3, batches:    500, num_examples:   8000, 71.3 samples/sec, epoch time so far:  0:01:52.211026\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:11 INFO 140004883121984] #quality_metric: host=algo-1, epoch=3, batch=589 train cross_entropy <loss>=(0.4888804433681551)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:11 INFO 140004883121984] #quality_metric: host=algo-1, epoch=3, batch=589 train smooth_l1 <loss>=(0.30288459090323205)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:11 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:11 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:37 INFO 140004883121984] #quality_metric: host=algo-1, epoch=3, validation mAP <score>=(0.9352541534060551)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:37 INFO 140004883121984] Updating the best model with validation-mAP=0.9352541534060551\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:37 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:37 INFO 140004883121984] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1606376557.45096, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 3}, \"StartTime\": 1606376399.773186}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:42:59 INFO 140004883121984] Epoch:    4, batches:    100, num_examples:   1600, 72.3 samples/sec, epoch time so far:  0:00:22.118345\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:43:21 INFO 140004883121984] Epoch:    4, batches:    200, num_examples:   3200, 72.2 samples/sec, epoch time so far:  0:00:44.347288\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:43:44 INFO 140004883121984] Epoch:    4, batches:    300, num_examples:   4800, 71.7 samples/sec, epoch time so far:  0:01:06.966817\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:06 INFO 140004883121984] Epoch:    4, batches:    400, num_examples:   6400, 71.9 samples/sec, epoch time so far:  0:01:29.001958\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:28 INFO 140004883121984] Epoch:    4, batches:    500, num_examples:   8000, 72.0 samples/sec, epoch time so far:  0:01:51.160189\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:48 INFO 140004883121984] #quality_metric: host=algo-1, epoch=4, batch=589 train cross_entropy <loss>=(0.45623736132832715)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:48 INFO 140004883121984] #quality_metric: host=algo-1, epoch=4, batch=589 train smooth_l1 <loss>=(0.25984780167387506)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:48 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:44:48 INFO 140004883121984] Updated the metrics\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[11/26/2020 07:45:13 INFO 140004883121984] #quality_metric: host=algo-1, epoch=4, validation mAP <score>=(0.9356644968313633)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:45:13 INFO 140004883121984] Updating the best model with validation-mAP=0.9356644968313633\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:45:13 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:45:13 INFO 140004883121984] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1606376713.81965, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 4}, \"StartTime\": 1606376557.45117}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:45:36 INFO 140004883121984] Epoch:    5, batches:    100, num_examples:   1600, 70.2 samples/sec, epoch time so far:  0:00:22.793185\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:45:58 INFO 140004883121984] Epoch:    5, batches:    200, num_examples:   3200, 71.1 samples/sec, epoch time so far:  0:00:45.003180\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:46:21 INFO 140004883121984] Epoch:    5, batches:    300, num_examples:   4800, 71.1 samples/sec, epoch time so far:  0:01:07.492837\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:46:44 INFO 140004883121984] Epoch:    5, batches:    400, num_examples:   6400, 70.8 samples/sec, epoch time so far:  0:01:30.366162\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:06 INFO 140004883121984] Epoch:    5, batches:    500, num_examples:   8000, 71.1 samples/sec, epoch time so far:  0:01:52.560878\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:26 INFO 140004883121984] #quality_metric: host=algo-1, epoch=5, batch=590 train cross_entropy <loss>=(0.42184248318147116)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:26 INFO 140004883121984] #quality_metric: host=algo-1, epoch=5, batch=590 train smooth_l1 <loss>=(0.22768806695657634)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:26 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:26 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:52 INFO 140004883121984] #quality_metric: host=algo-1, epoch=5, validation mAP <score>=(0.962914982391031)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:52 INFO 140004883121984] Updating the best model with validation-mAP=0.962914982391031\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:52 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:47:52 INFO 140004883121984] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1606376872.540739, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 5}, \"StartTime\": 1606376713.819823}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:48:14 INFO 140004883121984] Epoch:    6, batches:    100, num_examples:   1600, 71.9 samples/sec, epoch time so far:  0:00:22.264262\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:48:37 INFO 140004883121984] Epoch:    6, batches:    200, num_examples:   3200, 71.9 samples/sec, epoch time so far:  0:00:44.509931\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:48:59 INFO 140004883121984] Epoch:    6, batches:    300, num_examples:   4800, 71.5 samples/sec, epoch time so far:  0:01:07.101473\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:49:21 INFO 140004883121984] Epoch:    6, batches:    400, num_examples:   6400, 71.8 samples/sec, epoch time so far:  0:01:29.188106\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:49:44 INFO 140004883121984] Epoch:    6, batches:    500, num_examples:   8000, 71.7 samples/sec, epoch time so far:  0:01:51.639572\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:03 INFO 140004883121984] #quality_metric: host=algo-1, epoch=6, batch=589 train cross_entropy <loss>=(0.39526467408285954)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:03 INFO 140004883121984] #quality_metric: host=algo-1, epoch=6, batch=589 train smooth_l1 <loss>=(0.2015706415760998)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:03 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:04 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:27 INFO 140004883121984] #quality_metric: host=algo-1, epoch=6, validation mAP <score>=(0.9734963651406314)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:27 INFO 140004883121984] Updating the best model with validation-mAP=0.9734963651406314\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:27 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:27 INFO 140004883121984] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1606377027.365131, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 6}, \"StartTime\": 1606376872.540943}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:50:49 INFO 140004883121984] Epoch:    7, batches:    100, num_examples:   1600, 70.8 samples/sec, epoch time so far:  0:00:22.594410\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:51:12 INFO 140004883121984] Epoch:    7, batches:    200, num_examples:   3200, 71.2 samples/sec, epoch time so far:  0:00:44.942574\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:51:34 INFO 140004883121984] Epoch:    7, batches:    300, num_examples:   4800, 71.6 samples/sec, epoch time so far:  0:01:07.084864\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:51:56 INFO 140004883121984] Epoch:    7, batches:    400, num_examples:   6400, 71.7 samples/sec, epoch time so far:  0:01:29.322113\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:52:18 INFO 140004883121984] Epoch:    7, batches:    500, num_examples:   8000, 72.0 samples/sec, epoch time so far:  0:01:51.133967\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:52:36 INFO 140004883121984] #quality_metric: host=algo-1, epoch=7, batch=589 train cross_entropy <loss>=(0.370094586601376)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:52:36 INFO 140004883121984] #quality_metric: host=algo-1, epoch=7, batch=589 train smooth_l1 <loss>=(0.1811344247768825)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:52:36 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:52:37 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:53:00 INFO 140004883121984] #quality_metric: host=algo-1, epoch=7, validation mAP <score>=(0.9826667101240081)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:53:00 INFO 140004883121984] Updating the best model with validation-mAP=0.9826667101240081\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:53:00 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:53:00 INFO 140004883121984] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1606377180.979403, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 7}, \"StartTime\": 1606377027.365353}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[11/26/2020 07:53:24 INFO 140004883121984] Epoch:    8, batches:    100, num_examples:   1600, 68.1 samples/sec, epoch time so far:  0:00:23.479335\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:53:46 INFO 140004883121984] Epoch:    8, batches:    200, num_examples:   3200, 70.5 samples/sec, epoch time so far:  0:00:45.405800\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:54:09 INFO 140004883121984] Epoch:    8, batches:    300, num_examples:   4800, 70.5 samples/sec, epoch time so far:  0:01:08.125744\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:54:30 INFO 140004883121984] Epoch:    8, batches:    400, num_examples:   6400, 71.5 samples/sec, epoch time so far:  0:01:29.530157\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:54:52 INFO 140004883121984] Epoch:    8, batches:    500, num_examples:   8000, 71.6 samples/sec, epoch time so far:  0:01:51.665903\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:12 INFO 140004883121984] #quality_metric: host=algo-1, epoch=8, batch=590 train cross_entropy <loss>=(0.35405305322866487)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:12 INFO 140004883121984] #quality_metric: host=algo-1, epoch=8, batch=590 train smooth_l1 <loss>=(0.1640302491852702)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:12 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:12 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:35 INFO 140004883121984] #quality_metric: host=algo-1, epoch=8, validation mAP <score>=(0.9878697947165613)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:35 INFO 140004883121984] Updating the best model with validation-mAP=0.9878697947165613\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:35 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:35 INFO 140004883121984] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1606377335.734673, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 8}, \"StartTime\": 1606377180.979553}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:55:58 INFO 140004883121984] Epoch:    9, batches:    100, num_examples:   1600, 71.9 samples/sec, epoch time so far:  0:00:22.266466\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:56:20 INFO 140004883121984] Epoch:    9, batches:    200, num_examples:   3200, 72.2 samples/sec, epoch time so far:  0:00:44.310769\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:56:42 INFO 140004883121984] Epoch:    9, batches:    300, num_examples:   4800, 72.3 samples/sec, epoch time so far:  0:01:06.370687\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:04 INFO 140004883121984] Epoch:    9, batches:    400, num_examples:   6400, 72.4 samples/sec, epoch time so far:  0:01:28.435488\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:25 INFO 140004883121984] Epoch:    9, batches:    500, num_examples:   8000, 72.6 samples/sec, epoch time so far:  0:01:50.119021\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:45 INFO 140004883121984] #quality_metric: host=algo-1, epoch=9, batch=589 train cross_entropy <loss>=(0.34207342559627435)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:45 INFO 140004883121984] #quality_metric: host=algo-1, epoch=9, batch=589 train smooth_l1 <loss>=(0.1540209696161614)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:45 INFO 140004883121984] Round of batches complete\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:57:46 INFO 140004883121984] Updated the metrics\u001b[0m\n",
      "\n",
      "2020-11-26 07:58:11 Uploading - Uploading generated training model\u001b[34m[11/26/2020 07:58:03 INFO 140004883121984] #quality_metric: host=algo-1, epoch=9, validation mAP <score>=(0.9865307283468561)\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:58:03 INFO 140004883121984] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1606377483.640166, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 9}, \"StartTime\": 1606377335.734829}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:58:03 WARNING 140004883121984] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:58:03 INFO 140004883121984] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/26/2020 07:58:03 INFO 140004883121984] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"totaltime\": {\"count\": 1, \"max\": 1593546.6799736023, \"sum\": 1593546.6799736023, \"min\": 1593546.6799736023}, \"setuptime\": {\"count\": 1, \"max\": 9.725093841552734, \"sum\": 9.725093841552734, \"min\": 9.725093841552734}}, \"EndTime\": 1606377484.407976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1606375890.99926}\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-26 07:58:32 Completed - Training job completed\n",
      "Training seconds: 1703\n",
      "Billable seconds: 1703\n",
      "CPU times: user 3.99 s, sys: 154 ms, total: 4.14 s\n",
      "Wall time: 31min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "client = boto3.client('logs')\n",
    "BASE_LOG_NAME = '/aws/sagemaker/TrainingJobs'\n",
    "\n",
    "def plot_object_detection_log(model, title):\n",
    "    logs = client.describe_log_streams(logGroupName=BASE_LOG_NAME, logStreamNamePrefix=model._current_job_name)\n",
    "    cw_log = client.get_log_events(logGroupName=BASE_LOG_NAME, logStreamName=logs['logStreams'][0]['logStreamName'])\n",
    "\n",
    "    mAP_accs=[]\n",
    "    for e in cw_log['events']:\n",
    "        msg = e['message']\n",
    "        if 'validation mAP <score>=' in msg:\n",
    "            num_start = msg.find('(')\n",
    "            num_end = msg.find(')')\n",
    "            mAP = msg[num_start+1:num_end]\n",
    "            mAP_accs.append(float(mAP))\n",
    "\n",
    "    print(title)\n",
    "    print('Maximum mAP: %f ' % max(mAP_accs))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Mean Avg Precision (mAP)')\n",
    "    val_plot,   = ax.plot(range(len(mAP_accs)),   mAP_accs,   label='mAP')\n",
    "    plt.legend(handles=[val_plot])\n",
    "    ax.yaxis.set_ticks(np.arange(0.0, 1.05, 0.1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2f'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP tracking for job: object-detection-2020-11-26-07-27-10-908\n",
      "Maximum mAP: 0.987870 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_object_detection_log(od_model, 'mAP tracking for job: ' + od_model._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating the Model with the training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://deeplens-sziit/DEMO-ObjectDetection-birds/output/object-detection-2020-11-26-07-27-10-908/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:966911974471:model/object-detection-2020-11-26-07-27-10-908-mod\n",
      "The Model Name is as: object-detection-2020-11-26-07-27-10-908-mod\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "info = sm.describe_training_job(TrainingJobName=od_model._current_job_name)\n",
    "model_name=od_model._current_job_name+'-mod'\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])\n",
    "print('The Model Name is as: ' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
