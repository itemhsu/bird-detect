{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Generate RecordIO files\n",
    "\n",
    "The [Caltech Birds (CUB 200 2011)](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) dataset contains 11,788 images across 200 bird species (the original technical report can be found [here](http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf)).  Each species comes with around 60 images, with a typical size of about 350 pixels by 500 pixels.  Bounding boxes are provided, as are annotations of bird parts.  A recommended train/test split is given, but image size data is not.\n",
    "\n",
    "![](./cub_200_2011_snapshot.png)\n",
    "\n",
    "The dataset can be downloaded [here](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html).\n",
    "\n",
    "## Step 0: Download and unpack the dataset\n",
    "\n",
    "Here we download the birds dataset from CalTech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "import conf\n",
    "#print(conf.num_epochs)\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download ('https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11788\n",
      "CPU times: user 180 ms, sys: 23.8 ms, total: 204 ms\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean up prior version of the downloaded dataset if you are running this again\n",
    "!rm -rf CUB_200_2011  \n",
    "\n",
    "# Unpack and then remove the downloaded compressed tar file\n",
    "!gunzip -c ./CUB_200_2011.tgz | tar xopf - \n",
    "\n",
    "def combine(manyCalss, oneClass):\n",
    "    file = open(manyCalss, \"r\")\n",
    "    line_count = 0\n",
    "    for line in file:\n",
    "        if line != \"\\n\":\n",
    "            line_count += 1\n",
    "    file.close()\n",
    "\n",
    "    print(line_count)\n",
    "\n",
    "    file_object = open(oneClass, 'w')\n",
    "    for ii in range(line_count):\n",
    "        file_object.write('{} 1\\n'.format(ii+1))\n",
    "    file_object.close()\n",
    "\n",
    "\n",
    "combine(\"CUB_200_2011/image_class_labels.txt\", \"CUB_200_2011/one_image_class_labels.txt\")\n",
    "#combine(\"CUB_200_2011/image_class_labels.txt\", \"CUB_200_2011/one_image_class_labels.txt\")\n",
    "!echo \"1 001.bird\" > CUB_200_2011/one_classes.txt\n",
    "#!rm CUB_200_2011.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client(service_name='runtime.sagemaker')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SPLIT = True\n",
    "\n",
    "\n",
    "\n",
    "# To speed up training and experimenting, you can use a small handful of species.\n",
    "# To see the full list of the classes available, look at the content of CLASSES_FILE.\n",
    "\n",
    "CLASSES = [1]\n",
    "print(CLASSES)\n",
    "RESIZE_SIZE = 256\n",
    "\n",
    "BASE_DIR   = 'CUB_200_2011/'\n",
    "IMAGES_DIR = BASE_DIR + 'images/'\n",
    "\n",
    "CLASSES_FILE = BASE_DIR + 'one_classes.txt'\n",
    "BBOX_FILE    = BASE_DIR + 'bounding_boxes.txt'\n",
    "IMAGE_FILE   = BASE_DIR + 'images.txt'\n",
    "LABEL_FILE   = BASE_DIR + 'one_image_class_labels.txt'\n",
    "SIZE_FILE    = BASE_DIR + 'sizes.txt'\n",
    "SPLIT_FILE   = BASE_DIR + 'train_test_split.txt'\n",
    "\n",
    "TRAIN_LST_FILE = 'birds_ssd_train.lst'\n",
    "VAL_LST_FILE   = 'birds_ssd_val.lst'\n",
    "\n",
    "TRAIN_RATIO     = 0.8\n",
    "CLASS_COLS      = ['class_number','class_id']\n",
    "IM2REC_SSD_COLS = ['header_cols', 'label_width', 'zero_based_id', 'xmin', 'ymin', 'xmax', 'ymax', 'image_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_df = pd.read_csv(CLASSES_FILE, sep=' ', names=CLASS_COLS, header=None)\n",
    "#criteria = classes_df['class_number'].isin(CLASSES)\n",
    "#classes_df = classes_df[criteria]\n",
    "#print(classes_df.to_csv(columns=['class_id'], sep='\\t', index=False, header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Gather image sizes\n",
    "\n",
    "For this particular dataset, bounding box annotations are specified in absolute terms.  RecordIO format requires them to be defined in terms relative to the image size.  The following code visits each image, extracts the height and width, and saves this information into a file for subsequent use.  Some other publicly available datasets provide such a file for exactly this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a file containing image sizes...\n",
      "Image sizes:\n",
      "   idx  width  height\n",
      "0    1    500     335\n",
      "1    2    500     336\n",
      "2    3    500     347\n",
      "3    4    415     500\n",
      "4    5    331     380\n",
      "CPU times: user 45.3 s, sys: 855 ms, total: 46.1 s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SIZE_COLS = ['idx','width','height']\n",
    "\n",
    "def gen_image_size_file():\n",
    "    print('Generating a file containing image sizes...')\n",
    "    images_df = pd.read_csv(IMAGE_FILE, sep=' ',\n",
    "                            names=['image_pretty_name', 'image_file_name'],\n",
    "                            header=None)\n",
    "    rows_list = []\n",
    "    idx = 0\n",
    "    for i in images_df['image_file_name']:\n",
    "        # TODO: add progress bar\n",
    "        idx += 1\n",
    "        img = cv2.imread(IMAGES_DIR + i)\n",
    "        dimensions = img.shape\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        image_dict = {'idx': idx, 'width': width, 'height': height}\n",
    "        rows_list.append(image_dict)\n",
    "\n",
    "    sizes_df = pd.DataFrame(rows_list)\n",
    "    print('Image sizes:\\n' + str(sizes_df.head()))\n",
    "\n",
    "    sizes_df[SIZE_COLS].to_csv(SIZE_FILE, sep=' ', index=False, header=None)\n",
    "\n",
    "gen_image_size_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Generate list files for producing RecordIO files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_test(df, label_column, train_frac=0.8):\n",
    "    train_df, test_df = pd.DataFrame(), pd.DataFrame()\n",
    "    labels = df[label_column].unique()\n",
    "    for lbl in labels:\n",
    "        lbl_df = df[df[label_column] == lbl]\n",
    "        lbl_train_df = lbl_df.sample(frac=train_frac)\n",
    "        lbl_test_df = lbl_df.drop(lbl_train_df.index)\n",
    "        print('\\n{}:\\n---------\\ntotal:{}\\ntrain_df:{}\\ntest_df:{}'.format(lbl, len(lbl_df), len(lbl_train_df), len(lbl_test_df)))\n",
    "        train_df = train_df.append(lbl_train_df)\n",
    "        test_df = test_df.append(lbl_test_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "def gen_list_files():\n",
    "    # use generated sizes file\n",
    "    sizes_df = pd.read_csv(SIZE_FILE, sep=' ',\n",
    "                names=['image_pretty_name', 'width', 'height'],\n",
    "                header=None)\n",
    "    bboxes_df = pd.read_csv(BBOX_FILE, sep=' ',\n",
    "                names=['image_pretty_name', 'x_abs', 'y_abs', 'bbox_width', 'bbox_height'],\n",
    "                header=None)\n",
    "    split_df = pd.read_csv(SPLIT_FILE, sep=' ',\n",
    "                            names=['image_pretty_name', 'is_training_image'],\n",
    "                            header=None)\n",
    "    print(IMAGE_FILE)\n",
    "    images_df = pd.read_csv(IMAGE_FILE, sep=' ',\n",
    "                            names=['image_pretty_name', 'image_file_name'],\n",
    "                            header=None)\n",
    "    print('num images total: ' + str(images_df.shape[0]))\n",
    "    image_class_labels_df = pd.read_csv(LABEL_FILE, sep=' ',\n",
    "                                names=['image_pretty_name', 'class_id'], header=None)\n",
    "\n",
    "    # Merge the metadata into a single flat dataframe for easier processing\n",
    "    full_df = pd.DataFrame(images_df)\n",
    "    full_df.reset_index(inplace=True)\n",
    "    full_df = pd.merge(full_df, image_class_labels_df, on='image_pretty_name')\n",
    "    full_df = pd.merge(full_df, sizes_df, on='image_pretty_name')\n",
    "    full_df = pd.merge(full_df, bboxes_df, on='image_pretty_name')\n",
    "    full_df = pd.merge(full_df, split_df, on='image_pretty_name')\n",
    "    full_df.sort_values(by=['index'], inplace=True)\n",
    "\n",
    "    # Define the bounding boxes in the format required by SageMaker's built in Object Detection algorithm.\n",
    "    # the xmin/ymin/xmax/ymax parameters are specified as ratios to the total image pixel size\n",
    "    full_df['header_cols'] = 2  # one col for the number of header cols, one for the label width\n",
    "    full_df['label_width'] = 5  # number of cols for each label: class, xmin, ymin, xmax, ymax\n",
    "    full_df['xmin'] = full_df['x_abs'] / full_df['width']\n",
    "    full_df['xmax'] = (full_df['x_abs'] + full_df['bbox_width']) / full_df['width']\n",
    "    full_df['ymin'] = full_df['y_abs'] / full_df['height']\n",
    "    full_df['ymax'] = (full_df['y_abs'] + full_df['bbox_height']) / full_df['height']\n",
    "\n",
    "    # object detection class id's must be zero based. map from\n",
    "    # class_id's given by CUB to zero-based (1 is 0, and 200 is 199).\n",
    "\n",
    "    \n",
    "    unique_classes = full_df['class_id'].drop_duplicates()\n",
    "    sorted_unique_classes = sorted(unique_classes)\n",
    "\n",
    "    id_to_zero = {}\n",
    "    i = 0.0\n",
    "    for c in sorted_unique_classes:\n",
    "        id_to_zero[c] = i\n",
    "        i += 1.0\n",
    "\n",
    "    full_df['zero_based_id'] = full_df['class_id'].map(id_to_zero)\n",
    "\n",
    "    full_df.reset_index(inplace=True)\n",
    "\n",
    "    # use 4 decimal places, as it seems to be required by the Object Detection algorithm\n",
    "    pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "    train_df = []\n",
    "    val_df = []\n",
    "\n",
    "    # split into training and validation sets\n",
    "    train_df, val_df = split_to_train_test(full_df, 'class_id', TRAIN_RATIO)\n",
    "\n",
    "    train_df[IM2REC_SSD_COLS].to_csv(TRAIN_LST_FILE, sep='\\t',float_format='%.4f', header=None)\n",
    "    val_df[IM2REC_SSD_COLS].to_csv(VAL_LST_FILE, sep='\\t',float_format='%.4f', header=None)\n",
    "        \n",
    "    print('num train: ' + str(train_df.shape[0]))\n",
    "    print('num val: ' + str(val_df.shape[0]))\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUB_200_2011/images.txt\n",
      "num images total: 11788\n",
      "\n",
      "1:\n",
      "---------\n",
      "total:11788\n",
      "train_df:9430\n",
      "test_df:2358\n",
      "num train: 9430\n",
      "num val: 2358\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = gen_list_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Convert data into RecordIO format\n",
    "\n",
    "Now we create im2rec databases (.rec files) for training and validation based on the list files created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/object_detection_birds_2020-11-20/birds_ssd_train.lst in /home/ec2-user/SageMaker/object_detection_birds_2020-11-20\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.007500648498535156  count: 0\n",
      "time: 6.310894727706909  count: 1000\n",
      "time: 6.302682161331177  count: 2000\n",
      "time: 6.378289699554443  count: 3000\n",
      "time: 6.28742241859436  count: 4000\n",
      "time: 6.34315824508667  count: 5000\n",
      "time: 6.32803201675415  count: 6000\n",
      "time: 6.27110743522644  count: 7000\n",
      "time: 6.419079780578613  count: 8000\n",
      "time: 6.3166420459747314  count: 9000\n",
      "Creating .rec file from /home/ec2-user/SageMaker/object_detection_birds_2020-11-20/birds_ssd_val.lst in /home/ec2-user/SageMaker/object_detection_birds_2020-11-20\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.005661725997924805  count: 0\n",
      "time: 6.2773332595825195  count: 1000\n",
      "time: 6.387125253677368  count: 2000\n"
     ]
    }
   ],
   "source": [
    "!python tools/im2rec.py --resize $RESIZE_SIZE --pack-label birds_ssd $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Upload RecordIO files to S3\n",
    "Upload the training and validation data to the S3 bucket. We do this in multiple channels. Channels are simply directories in the bucket that differentiate the types of data provided to the algorithm. For the object detection algorithm, we call these directories `train` and `validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://deeplens-sziit/DEMO-ObjectDetection-birds/validation/birds_ssd_val.rec'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "train_channel = conf.prefix + '/train'\n",
    "validation_channel = conf.prefix + '/validation'\n",
    "sagemaker.s3.S3Uploader.upload(\"birds_ssd_train.rec\", f\"s3://{conf.bucket}/{train_channel}\")\n",
    "sagemaker.s3.S3Uploader.upload(\"birds_ssd_val.rec\", f\"s3://{conf.bucket}/{validation_channel}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
